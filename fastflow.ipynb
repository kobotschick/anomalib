{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd19a962-8ed3-4dff-a7c5-bb70094f39e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/bin/python\n",
      "['/notebooks', '/notebooks/.anomalib_env/lib/python38.zip', '/notebooks/.anomalib_env/lib/python3.8', '/notebooks/.anomalib_env/lib/python3.8/lib-dynload', '', '/notebooks/.anomalib_env/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1ae108-226b-4526-9058-fd063c1bf6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np: 1.22.3\n",
      "torch: 1.11.0\n",
      "cuda enable: True\n",
      "current_device: 0\n",
      "device: <torch.cuda.device object at 0x7f0c9d7f5e20>\n",
      "device_count: 1\n",
      "get_device_name: Quadro P5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(f'np: {np.__version__}')\n",
    "print(f'torch: {torch.__version__}')\n",
    "\n",
    "print(f'cuda enable: {torch.cuda.is_available()}')\n",
    "print(f'current_device: {torch.cuda.current_device()}')\n",
    "print(f'device: {torch.cuda.device(0)}')\n",
    "print(f'device_count: {torch.cuda.device_count()}')\n",
    "print(f'get_device_name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00550b1-2fea-4ac8-a47f-13c343810f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNF coder: 128\n",
      "CNF coder: 256\n",
      "CNF coder: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:439: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  rank_zero_warn(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:52: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.\n",
      "  rank_zero_deprecation(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:81: LightningDeprecationWarning: Setting `prepare_data_per_node` with the trainer flag is deprecated in v1.5.0 and will be removed in v1.7.0. Please set `prepare_data_per_node` in `LightningDataModule` and/or `LightningModule` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:572: LightningDeprecationWarning: Trainer argument `terminate_on_nan` was deprecated in v1.5 and will be removed in 1.7. Please use `Trainer(detect_anomaly=True)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:61: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=100)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.\n",
      "  rank_zero_deprecation(\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /notebooks/results/fastflow/mvtec/cable/weights exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | image_threshold       | AdaptiveThreshold        | 0     \n",
      "1 | pixel_threshold       | AdaptiveThreshold        | 0     \n",
      "2 | training_distribution | AnomalyScoreDistribution | 0     \n",
      "3 | min_max               | MinMax                   | 0     \n",
      "4 | image_metrics         | MetricCollection         | 0     \n",
      "5 | pixel_metrics         | MetricCollection         | 0     \n",
      "6 | model                 | FastflowModel            | 64.1 M\n",
      "-------------------------------------------------------------------\n",
      "41.3 M    Trainable params\n",
      "22.7 M    Non-trainable params\n",
      "64.1 M    Total params\n",
      "256.236   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  58%|█████▊    | 7/12 [00:15<00:11,  2.28s/it]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:10<?, ?it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 8/12 [00:27<00:13,  3.39s/it]:44, 11.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/anomalib/models/fastflow/model.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_norm = torch.tensor(distribution[layer_idx], dtype=torch.double)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  75%|███████▌  | 9/12 [00:27<00:09,  3.04s/it]:17,  5.71s/it]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 10/12 [00:27<00:05,  2.77s/it]07,  3.89s/it]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 11/12 [00:27<00:02,  2.54s/it]02,  2.99s/it]\u001b[A\n",
      "Epoch 0: 100%|██████████| 12/12 [00:31<00:00,  2.63s/it]00,  2.44s/it]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 7/12 [00:50<00:35,  7.15s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 8/12 [01:03<00:31,  7.93s/it]:51, 12.98s/it]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 9/12 [01:03<00:21,  7.08s/it]:19,  6.63s/it]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 10/12 [01:03<00:12,  6.40s/it]09,  4.51s/it]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 11/12 [01:04<00:05,  5.84s/it]03,  3.45s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 12/12 [01:09<00:00,  5.83s/it]00,  2.81s/it]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 7/12 [01:39<01:11, 14.25s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:20<?, ?it/s]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 8/12 [02:00<01:00, 15.06s/it]:21, 20.38s/it]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 9/12 [02:00<00:40, 13.41s/it]:30, 10.32s/it]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 10/12 [02:00<00:24, 12.10s/it]13,  6.96s/it]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 11/12 [02:01<00:11, 11.02s/it]05,  5.29s/it]\u001b[A\n",
      "Epoch 2: 100%|██████████| 12/12 [02:07<00:00, 10.64s/it]00,  4.27s/it]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 7/12 [02:27<01:45, 21.13s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 8/12 [02:41<01:20, 20.20s/it]:52, 13.19s/it]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 9/12 [02:41<00:53, 17.99s/it]:20,  6.74s/it]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 10/12 [02:42<00:32, 16.22s/it]09,  4.59s/it]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 11/12 [02:42<00:14, 14.77s/it]03,  3.51s/it]\u001b[A\n",
      "Epoch 3: 100%|██████████| 12/12 [02:52<00:00, 14.41s/it]00,  2.86s/it]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 7/12 [03:09<02:15, 27.05s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 8/12 [03:22<01:41, 25.36s/it]:52, 13.14s/it]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 9/12 [03:23<01:07, 22.57s/it]:20,  6.70s/it]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 10/12 [03:23<00:40, 20.34s/it]09,  4.55s/it]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 11/12 [03:23<00:18, 18.51s/it]03,  3.48s/it]\u001b[A\n",
      "Epoch 4: 100%|██████████| 12/12 [03:34<00:00, 17.88s/it]00,  2.82s/it]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 7/12 [03:50<02:44, 32.88s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:11<?, ?it/s]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 8/12 [04:02<02:01, 30.31s/it]:47, 11.91s/it]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 9/12 [04:02<01:20, 26.97s/it]:18,  6.09s/it]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 10/12 [04:02<00:48, 24.30s/it]08,  4.14s/it]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 11/12 [04:03<00:22, 22.12s/it]03,  3.18s/it]\u001b[A\n",
      "Epoch 5: 100%|██████████| 12/12 [04:15<00:00, 21.26s/it]00,  2.59s/it]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 7/12 [04:31<03:14, 38.85s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 8/12 [04:45<02:22, 35.69s/it]:52, 13.12s/it]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 9/12 [04:45<01:35, 31.75s/it]:20,  6.69s/it]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 10/12 [04:46<00:57, 28.60s/it]09,  4.55s/it]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 11/12 [04:46<00:26, 26.02s/it]03,  3.48s/it]\u001b[A\n",
      "Epoch 6: 100%|██████████| 12/12 [05:00<00:00, 25.03s/it]00,  2.83s/it]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 7/12 [05:20<03:49, 45.83s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:13<?, ?it/s]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 8/12 [05:35<02:47, 41.88s/it]:54, 13.55s/it]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 9/12 [05:35<01:51, 37.26s/it]:20,  6.96s/it]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 10/12 [05:35<01:07, 33.56s/it]09,  4.73s/it]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 11/12 [05:35<00:30, 30.54s/it]03,  3.62s/it]\u001b[A\n",
      "Epoch 7: 100%|██████████| 12/12 [05:56<00:00, 29.71s/it]00,  2.94s/it]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 7/12 [06:12<04:26, 53.27s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 8/12 [06:25<03:12, 48.24s/it]:50, 12.62s/it]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 9/12 [06:26<02:08, 42.91s/it]:19,  6.44s/it]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 10/12 [06:26<01:17, 38.64s/it]08,  4.38s/it]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 11/12 [06:26<00:35, 35.15s/it]03,  3.35s/it]\u001b[A\n",
      "Epoch 8: 100%|██████████| 12/12 [06:44<00:00, 33.69s/it]00,  2.73s/it]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 7/12 [07:06<05:04, 60.92s/it]               \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:13<?, ?it/s]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 8/12 [07:20<03:40, 55.03s/it]:53, 13.26s/it]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 9/12 [07:20<02:26, 48.95s/it]:20,  6.78s/it]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 10/12 [07:20<01:28, 44.08s/it]09,  4.61s/it]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 11/12 [07:21<00:40, 40.10s/it]03,  3.52s/it]\u001b[A\n",
      "Epoch 9: 100%|██████████| 12/12 [07:46<00:00, 38.84s/it]00,  2.87s/it]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 7/12 [08:08<05:48, 69.74s/it]              \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:14<?, ?it/s]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 8/12 [08:23<04:11, 62.92s/it]58, 14.64s/it]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 9/12 [08:23<02:47, 55.96s/it]22,  7.46s/it]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 10/12 [08:23<01:40, 50.39s/it]0,  5.06s/it]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 11/12 [08:24<00:45, 45.83s/it]3,  3.87s/it]\u001b[A\n",
      "Epoch 10: 100%|██████████| 12/12 [08:52<00:00, 44.37s/it]0,  3.15s/it]\u001b[A\n",
      "Epoch 11:  58%|█████▊    | 7/12 [09:09<06:32, 78.54s/it]              \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 11:  67%|██████▋   | 8/12 [09:22<04:41, 70.33s/it]50, 12.51s/it]\u001b[A\n",
      "Epoch 11:  75%|███████▌  | 9/12 [09:22<03:07, 62.55s/it]19,  6.38s/it]\u001b[A\n",
      "Epoch 11:  83%|████████▎ | 10/12 [09:23<01:52, 56.32s/it]8,  4.34s/it]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 11/12 [09:23<00:51, 51.22s/it]3,  3.32s/it]\u001b[A\n",
      "Epoch 11: 100%|██████████| 12/12 [09:46<00:00, 48.88s/it]0,  2.71s/it]\u001b[A\n",
      "Epoch 12:  58%|█████▊    | 7/12 [10:03<07:10, 86.17s/it]              \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 12:  67%|██████▋   | 8/12 [10:16<05:08, 77.02s/it]50, 12.59s/it]\u001b[A\n",
      "Epoch 12:  75%|███████▌  | 9/12 [10:16<03:25, 68.49s/it]19,  6.42s/it]\u001b[A\n",
      "Epoch 12:  83%|████████▎ | 10/12 [10:16<02:03, 61.67s/it]8,  4.37s/it]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 11/12 [10:16<00:56, 56.08s/it]3,  3.34s/it]\u001b[A\n",
      "Epoch 12: 100%|██████████| 12/12 [10:41<00:00, 53.49s/it]0,  2.72s/it]\u001b[A\n",
      "Epoch 13:  58%|█████▊    | 7/12 [10:58<07:50, 94.10s/it]              \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/5 [00:12<?, ?it/s]\u001b[A\n",
      "Epoch 13:  67%|██████▋   | 8/12 [11:12<05:36, 84.01s/it]51, 12.94s/it]\u001b[A\n",
      "Epoch 13:  75%|███████▌  | 9/12 [11:12<03:44, 74.72s/it]20,  6.68s/it]\u001b[A\n",
      "Epoch 13:  83%|████████▎ | 10/12 [11:12<02:14, 67.28s/it]9,  4.54s/it]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 11/12 [11:12<01:01, 61.18s/it]3,  3.47s/it]\u001b[A\n",
      "Epoch 13: 100%|██████████| 12/12 [11:40<00:00, 58.35s/it]0,  2.81s/it]\u001b[A\n",
      "Epoch 13: 100%|██████████| 12/12 [11:40<00:00, 58.35s/it]             \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 701.74573969841 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/5 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/anomalib/models/fastflow/model.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_norm = torch.tensor(distribution[layer_idx], dtype=torch.double)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:52<00:00, 10.41s/it]Testing took 52.352482080459595 seconds\n",
      "Throughput: 2.865193664924381 FPS\n",
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:52<00:00, 10.47s/it]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       image_AUROC          0.9250375032424927\n",
      "        image_F1            0.9171270728111267\n",
      "       pixel_AUROC           0.559411883354187\n",
      "        pixel_F1            0.06968194991350174\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from unittest.mock import patch\n",
    "from tools import train\n",
    "testargs = [\"\", \"--model\", \"fastflow\"]\n",
    "with patch.object(sys, 'argv', testargs):\n",
    "    train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ab023d-9e86-48e9-9394-86d258473775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNF coder: 512\n",
      "CNF coder: 1024\n",
      "CNF coder: 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:439: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  rank_zero_warn(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:52: LightningDeprecationWarning: Setting `max_steps = None` is deprecated in v1.5 and will no longer be supported in v1.7. Use `max_steps = -1` instead.\n",
      "  rank_zero_deprecation(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=True)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=True)`.\n",
      "  rank_zero_deprecation(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:81: LightningDeprecationWarning: Setting `prepare_data_per_node` with the trainer flag is deprecated in v1.5.0 and will be removed in v1.7.0. Please set `prepare_data_per_node` in `LightningDataModule` and/or `LightningModule` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:572: LightningDeprecationWarning: Trainer argument `terminate_on_nan` was deprecated in v1.5 and will be removed in 1.7. Please use `Trainer(detect_anomaly=True)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:61: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=100)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.\n",
      "  rank_zero_deprecation(\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(limit_predict_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/19 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/anomalib/models/fastflow/model.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_norm = torch.tensor(distribution[layer_idx], dtype=torch.double)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 19/19 [00:58<00:00,  3.08s/it]Testing took 257.47535037994385 seconds\n",
      "Throughput: 0.582580040297653 FPS\n",
      "Testing DataLoader 0: 100%|██████████| 19/19 [00:58<00:00,  3.10s/it]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       image_AUROC          0.9211019277572632\n",
      "        image_F1            0.9100528955459595\n",
      "       pixel_AUROC          0.4764419198036194\n",
      "        pixel_F1            0.06691201776266098\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from unittest.mock import patch\n",
    "from tools import test\n",
    "testargs = [\"\", \"--model\", \"fastflow\"]\n",
    "with patch.object(sys, 'argv', testargs):\n",
    "    test.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22165004-05c0-41fa-bd7e-5b1e46e2b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9c517e-aad8-44e1-ab64-69c5015f5495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image, ImageOps, ImageEnhance, PILLOW_VERSION\n",
    "PILLOW_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bac04a-f7d0-493a-88e1-c5764b44ebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/.anomalib_env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aca547c-4a02-43b6-b928-3a9968b7a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad3620c-7827-490c-8ec0-7b0c6c552622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : None\n",
      "       user config file : /root/.condarc\n",
      " populated config files : /opt/conda/.condarc\n",
      "          conda version : 4.11.0\n",
      "    conda-build version : 3.21.8\n",
      "         python version : 3.8.12.final.0\n",
      "       virtual packages : __cuda=11.6=0\n",
      "                          __linux=5.4.0=0\n",
      "                          __glibc=2.31=0\n",
      "                          __unix=0=0\n",
      "                          __archspec=1=x86_64\n",
      "       base environment : /opt/conda  (writable)\n",
      "      conda av data dir : /opt/conda/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://conda.anaconda.org/conda-forge/linux-64\n",
      "                          https://conda.anaconda.org/conda-forge/noarch\n",
      "          package cache : /opt/conda/pkgs\n",
      "                          /root/.conda/pkgs\n",
      "       envs directories : /opt/conda/envs\n",
      "                          /root/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/4.11.0 requests/2.26.0 CPython/3.8.12 Linux/5.4.0-89-generic ubuntu/20.04.3 glibc/2.31\n",
      "                UID:GID : 0:0\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a693eee0-e46c-47a7-9fdf-d20393cbdd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anomalib/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b41908-4cf4-489f-9864-186071afe2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda/envs/anomalib:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       1_gnu    conda-forge\n",
      "asttokens                 2.0.5              pyhd8ed1ab_0    conda-forge\n",
      "backcall                  0.2.0              pyh9f0ad1d_0    conda-forge\n",
      "backports                 1.0                        py_2    conda-forge\n",
      "backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\n",
      "bzip2                     1.0.8                h7f98852_4    conda-forge\n",
      "ca-certificates           2021.10.8            ha878542_0    conda-forge\n",
      "debugpy                   1.5.1           py310h122e73d_0    conda-forge\n",
      "decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\n",
      "entrypoints               0.4                pyhd8ed1ab_0    conda-forge\n",
      "executing                 0.8.3              pyhd8ed1ab_0    conda-forge\n",
      "ipykernel                 6.12.1          py310hfdc917e_0    conda-forge\n",
      "ipython                   8.2.0           py310hff52083_0    conda-forge\n",
      "jedi                      0.18.1          py310hff52083_1    conda-forge\n",
      "jupyter_client            7.2.2              pyhd8ed1ab_1    conda-forge\n",
      "jupyter_core              4.9.2           py310hff52083_0    conda-forge\n",
      "ld_impl_linux-64          2.36.1               hea4e1c9_2    conda-forge\n",
      "libffi                    3.4.2                h7f98852_5    conda-forge\n",
      "libgcc-ng                 11.2.0              h1d223b6_15    conda-forge\n",
      "libgomp                   11.2.0              h1d223b6_15    conda-forge\n",
      "libnsl                    2.0.0                h7f98852_0    conda-forge\n",
      "libsodium                 1.0.18               h36c2ea0_1    conda-forge\n",
      "libstdcxx-ng              11.2.0              he4da1e4_15    conda-forge\n",
      "libuuid                   2.32.1            h7f98852_1000    conda-forge\n",
      "libzlib                   1.2.11            h166bdaf_1014    conda-forge\n",
      "matplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge\n",
      "ncurses                   6.3                  h27087fc_1    conda-forge\n",
      "nest-asyncio              1.5.5              pyhd8ed1ab_0    conda-forge\n",
      "openssl                   3.0.2                h166bdaf_1    conda-forge\n",
      "packaging                 21.3               pyhd8ed1ab_0    conda-forge\n",
      "parso                     0.8.3              pyhd8ed1ab_0    conda-forge\n",
      "pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\n",
      "pip                       22.0.4             pyhd8ed1ab_0    conda-forge\n",
      "prompt-toolkit            3.0.29             pyha770c72_0    conda-forge\n",
      "psutil                    5.9.0           py310h5764c6d_1    conda-forge\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\n",
      "pure_eval                 0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "pygments                  2.11.2             pyhd8ed1ab_0    conda-forge\n",
      "pyparsing                 3.0.7              pyhd8ed1ab_0    conda-forge\n",
      "python                    3.10.4          h2660328_0_cpython    conda-forge\n",
      "python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\n",
      "python_abi                3.10                    2_cp310    conda-forge\n",
      "pyzmq                     22.3.0          py310h330234f_2    conda-forge\n",
      "readline                  8.1                  h46c0cb4_0    conda-forge\n",
      "setuptools                62.0.0          py310hff52083_0    conda-forge\n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\n",
      "sqlite                    3.37.1               h4ff8645_0    conda-forge\n",
      "stack_data                0.2.0              pyhd8ed1ab_0    conda-forge\n",
      "tk                        8.6.12               h27826a3_0    conda-forge\n",
      "tornado                   6.1             py310h5764c6d_3    conda-forge\n",
      "traitlets                 5.1.1              pyhd8ed1ab_0    conda-forge\n",
      "tzdata                    2022a                h191b570_0    conda-forge\n",
      "wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\n",
      "wheel                     0.37.1             pyhd8ed1ab_0    conda-forge\n",
      "xz                        5.2.5                h516909a_1    conda-forge\n",
      "zeromq                    4.3.4                h9c3ff4c_1    conda-forge\n",
      "zlib                      1.2.11            h166bdaf_1014    conda-forge\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbc90d-dcf7-4d2f-8216-7d4bb1da1375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomalib_env",
   "language": "python",
   "name": "anomalib_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
